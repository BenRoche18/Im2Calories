{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "food_classification_v1.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMEED9oymhB2SYDFZhAXOf8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenRoche18/Im2Calories/blob/master/food_classification_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_nLyDv8Vm2C",
        "colab_type": "text"
      },
      "source": [
        "# Set up environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISJ0ihdNdjhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import copy\n",
        "import shutil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlTFrxk9GwaH",
        "colab_type": "text"
      },
      "source": [
        "**Mount google drive**\n",
        "\n",
        "Mount google drive that contains project files and set to working directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FulAjqJxkLbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "PROJECT_DIR = os.path.join(\"drive\", \"My Drive\", \"Im2Calories\")\n",
        "os.chdir(PROJECT_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wjsABqdVyKa",
        "colab_type": "text"
      },
      "source": [
        "**Enable GPU**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rQNqPXEV4Ad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Running on\", device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8eHVTWDif9d",
        "colab_type": "text"
      },
      "source": [
        "**Declare parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y0qqicdirJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMAGE_SIZE = 299\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUlZthLcWNJT",
        "colab_type": "text"
      },
      "source": [
        "# Input data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylfT9aiQe-6J",
        "colab_type": "text"
      },
      "source": [
        "**Download Food101 dataset**\n",
        "\n",
        "I will be using the labelled food-101 dataset that includes 101 different classes each containing 1000 images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXbE44oDfDGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FOOD101_DIR = os.path.join(\"food-101\")\n",
        "\n",
        "if \"food-101\" not in os.listdir():\n",
        "  print(\"Downloading Food-101 dataset... \", end=\"\")\n",
        "  !wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
        "  print(\"Done\")\n",
        "  print(\"Extracting data... \", end=\"\")\n",
        "  !tar xzvf food-101.tar.gz\n",
        "  print(\"Done\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip_OHVgYkCft",
        "colab_type": "text"
      },
      "source": [
        "**Split dataset into training and validation images**\n",
        "\n",
        "The dataset comes with a train and testing split defined in two seperate text files, however for faster access we will copy the respective images into train and test directories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQx5SruSkBUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FOOD101_DIR = \"food-101\"\n",
        "TRAIN_DIR = os.path.join(FOOD101_DIR, \"train\")\n",
        "VAL_DIR = os.path.join(FOOD101_DIR, \"test\")\n",
        "\n",
        "print(\"Spliting dataset... \", end=\"\")\n",
        "images = {}\n",
        "\n",
        "for split in [\"train\", \"test\"]:\n",
        "  # extract image filenames\n",
        "  with open(os.path.join(FOOD101_DIR, \"meta\", split+\".txt\"), 'r') as file:\n",
        "    for path in file.readlines():\n",
        "      path = path.strip()\n",
        "      food_class, food_id = path.split('/')\n",
        "      images.setdefault(food_class, []).append(food_id)\n",
        "\n",
        "  # copy images into split directory\n",
        "  for food_class in images.keys():\n",
        "    # make class directory\n",
        "    class_dir = os.path.join(FOOD101_DIR, split, food_class)\n",
        "    if not os.path.exists(class_dir):\n",
        "      os.makedirs(class_dir)\n",
        "\n",
        "    # populate class directory with images\n",
        "    for food_id in images[food_class]:\n",
        "      src = os.path.join(FOOD101_DIR, \"images\", food_class, food_id+\".jpg\")\n",
        "      dest = os.path.join(FOOD101_DIR, split, food_class, food_id+\".jpg\")\n",
        "      if not os.path.exists(dest):\n",
        "        shutil.copy(src, dest)\n",
        "\n",
        "  images = {}\n",
        "\n",
        "print(\"Done\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBhOjkemhk6g",
        "colab_type": "text"
      },
      "source": [
        "**Format training images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZebSYMpiVto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transform = transforms.Compose([\n",
        "  transforms.RandomResizedCrop(IMAGE_SIZE),\n",
        "  transforms.RandomHorizontalFlip(),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_raw = torchvision.datasets.ImageFolder(TRAIN_DIR, transform=train_transform)\n",
        "train_size = len(train_raw)\n",
        "print(train_size)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_raw, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "class_names = train_raw.classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKkckr8PlU33",
        "colab_type": "text"
      },
      "source": [
        "**Format validation images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijBl6GS2mAnV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_transform = transforms.Compose([\n",
        "  transforms.Resize(350),\n",
        "  transforms.CenterCrop(IMAGE_SIZE),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_raw = torchvision.datasets.ImageFolder(VAL_DIR, transform=val_transform)\n",
        "val_size = len(val_raw)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_raw, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PStaUYeqlk12",
        "colab_type": "text"
      },
      "source": [
        "**Show example images from dataset**\n",
        "\n",
        "I have randomly selected and displayed 20 images from the training dataset along with their corresponding class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXJIlUvAmRJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols, rows = 5, 4\n",
        "fig = plt.figure(figsize=(20,10))\n",
        "fig.suptitle(\"Random images from dataset\")\n",
        "\n",
        "for i in range(1, cols*rows+1):\n",
        "  fig.add_subplot(rows, cols, i)\n",
        "\n",
        "  # randomly sellect image from dataset\n",
        "  j = np.random.randint(train_size)\n",
        "  img = train_raw[j][0].numpy()\n",
        "  img = np.transpose(img, (1,2,0))\n",
        "  img = img * (0.485, 0.456, 0.406) + (0.229, 0.224, 0.225)\n",
        "\n",
        "  plt.title(class_names[train_raw[j][1]])\n",
        "  plt.axis(\"off\")\n",
        "  img = np.clip(img, 0, 1)\n",
        "  plt.imshow(img, interpolation=\"nearest\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xzgyw9d1YtJx",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsiFng0jltpm",
        "colab_type": "text"
      },
      "source": [
        "**Fetch Model**\n",
        "\n",
        "In order to train the food classifier I will initially use transfer learning from a pretrained InceptionV3 model. This involves replacing the classification head with a 101-way dense layer and freezing all other layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBAfvknlm2kg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fetch pre-trained feature extractor\n",
        "model = torchvision.models.inception_v3(pretrained=True)\n",
        "\n",
        "# freeze feature extractor\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "\n",
        "model.aux_logits = False\n",
        "\n",
        "# extract number of features that are outputted in base model\n",
        "num_features = model.fc.in_features\n",
        "\n",
        "# replace classification head with 101-way dense layer\n",
        "model.fc = torch.nn.Linear(num_features, 101)\n",
        "\n",
        "model = model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvnnS8hWjPSV",
        "colab_type": "text"
      },
      "source": [
        "# Training via transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGOLOjPWHxtO",
        "colab_type": "text"
      },
      "source": [
        "**Declare optimizer and loss function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iK1NBW85H1q0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = torch.optim.SGD(model.fc.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
        "loss_func = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sg6d4uuPkWUM",
        "colab_type": "text"
      },
      "source": [
        "**Train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu2zJKlTnTQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "statistics = {\n",
        "    \"accuracy\": [],\n",
        "    \"val_accuracy\": []\n",
        "}\n",
        "\n",
        "def train():\n",
        "  best_acc = 0.0\n",
        "  best_model_weights = None\n",
        "\n",
        "  print(\"Training on {} images...\\n\".format(train_size))\n",
        "\n",
        "  for epoch in range(1, EPOCHS+1):\n",
        "    print(\"Epoch {}/{}...\".format(epoch, EPOCHS))\n",
        "\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    for (images, labels) in train_loader:\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # reset the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # fit images on model\n",
        "      outputs = model(images)\n",
        "      _, predictions = torch.max(outputs, 1)\n",
        "      loss = loss_func(outputs, labels)\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      running_loss += loss.item() * images.size(0)\n",
        "      running_corrects += torch.sum(predictions == labels.data)\n",
        "\n",
        "    # calculate statistics\n",
        "    epoch_loss = running_loss / train_size\n",
        "    epoch_acc = running_corrects.double() / train_size\n",
        "    \n",
        "    # print statistics\n",
        "    print(\"Training Loss: {:.4f}, Acc: {:.4f}\".format(epoch_loss, epoch_acc))\n",
        "\n",
        "    val_loss, val_acc = validate()\n",
        "\n",
        "    # save best model seen\n",
        "    if val_acc > best_acc:\n",
        "      best_acc = epoch_acc\n",
        "      best_model_weights = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    # print statistics\n",
        "    print(\"Validation Loss: {:.4f}, Acc: {:.4f}\\n\".format(val_loss, val_acc))\n",
        "\n",
        "  # reinstantiate best seen weights\n",
        "  model.load_state_dict(best_model_weights)\n",
        "\n",
        "  print(\"DONE\")\n",
        "\n",
        "\n",
        "def validate():\n",
        "  model.eval()\n",
        "  running_loss = 0.0\n",
        "  running_corrects = 0\n",
        "\n",
        "  for (images, labels) in val_loader:\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # fit images on model\n",
        "    with torch.no_grad():\n",
        "      outputs = model(images)\n",
        "      _, predictions = torch.max(outputs, 1)\n",
        "      loss = loss_func(outputs, labels)\n",
        "\n",
        "    running_loss += loss.item() * images.size(0)\n",
        "    running_corrects += torch.sum(predictions == labels.data)\n",
        "\n",
        "  # calculate statistics\n",
        "  val_loss = running_loss / val_size\n",
        "  val_acc = running_corrects.double() / val_size\n",
        "\n",
        "  return val_loss, val_acc\n",
        "\n",
        "\n",
        "train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toIULLBt1TBP",
        "colab_type": "text"
      },
      "source": [
        "**Save model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f407af0g1ZsG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_PATH = os.path.join(\"models\", \"food_classifier_TL_v1.pt\")\n",
        "\n",
        "torch.save(model.state_dict(), MODEL_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xGyA_WZrFd1",
        "colab_type": "text"
      },
      "source": [
        "**Evaluate transfer learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J0iqj-OrIqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(statistics['accuracy'], label='accuracy')\n",
        "plt.plot(statistics['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "I03gKxB1HNrs"
      },
      "source": [
        "# Training via fine-tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsIvaCgRMEad",
        "colab_type": "text"
      },
      "source": [
        "**Unfreeze layers in model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJ3e1KtmMHjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for param in model.parameters():\n",
        "  param.requires_grad = True\n",
        "\n",
        "EPOCHS = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3wLFxYsLUNd",
        "colab_type": "text"
      },
      "source": [
        "**Train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS1wVjE3MDp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "statistics = {\n",
        "    \"accuracy\": [],\n",
        "    \"val_accuracy\": []\n",
        "}\n",
        "\n",
        "train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "M8HmApoDkel8"
      },
      "source": [
        "**Save model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KNXCBYEGkel9",
        "colab": {}
      },
      "source": [
        "MODEL_PATH = os.path.join(\"models\", \"food_classifier_FT_v2\")\n",
        "\n",
        "torch.save(model.state_dict(), MODEL_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wHQgtDmp2nK",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B52JjtGBp4ZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(statistics['accuracy'], label='accuracy')\n",
        "plt.plot(statistics['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}