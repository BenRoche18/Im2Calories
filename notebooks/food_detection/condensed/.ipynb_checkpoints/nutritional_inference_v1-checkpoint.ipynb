{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import tensorflow.keras.utils as utils\n",
    "\n",
    "import os\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from usda import UsdaClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Declare parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.dirname(os.getcwd())\n",
    "\n",
    "IMAGE_SIZE = 512\n",
    "\n",
    "API_KEY = \"4INghUtThsIBWPTIcvfKyf0kNS6MtSXcC4R6mpNB\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Enable GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Running on\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fetch class names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rice',\n",
       " \"chicken-'n'-egg on rice\",\n",
       " 'beef curry',\n",
       " 'sushi',\n",
       " 'chicken rice',\n",
       " 'fried rice',\n",
       " 'toast',\n",
       " 'croissant',\n",
       " 'roll bread',\n",
       " 'raisin bread',\n",
       " 'hamburger',\n",
       " 'pizza',\n",
       " 'sandwiches',\n",
       " 'spaghetti',\n",
       " 'vegetable tempura',\n",
       " 'sausage',\n",
       " 'omelet',\n",
       " 'stew',\n",
       " 'fried fish',\n",
       " 'grilled salmon',\n",
       " 'sweet and sour pork',\n",
       " 'tempura',\n",
       " 'fried chicken',\n",
       " 'steak',\n",
       " 'egg sunny-side up',\n",
       " 'roast chicken',\n",
       " 'fried shrimp',\n",
       " 'potato salad',\n",
       " 'green salad',\n",
       " 'pizza toast',\n",
       " 'hot dog',\n",
       " 'french fries',\n",
       " 'mixed rice',\n",
       " 'green curry',\n",
       " 'paella',\n",
       " 'pancake',\n",
       " 'crape',\n",
       " 'tiramisu',\n",
       " 'waffle',\n",
       " 'shortcake',\n",
       " 'mushroom risotto',\n",
       " 'french toast',\n",
       " 'minestrone',\n",
       " 'chicken nugget',\n",
       " 'french bread',\n",
       " 'bagel',\n",
       " 'scone',\n",
       " 'tortilla',\n",
       " 'tacos',\n",
       " 'nachos',\n",
       " 'meat loaf',\n",
       " 'scrambled egg',\n",
       " 'lasagna',\n",
       " 'Caesar salad',\n",
       " 'oatmeal',\n",
       " 'muffin',\n",
       " 'popcorn',\n",
       " 'doughnut',\n",
       " 'apple pie',\n",
       " 'lamb kebabs',\n",
       " 'roast duck',\n",
       " 'hot pot',\n",
       " 'pork belly',\n",
       " 'custard tart',\n",
       " 'stir-fried mixed vegetables',\n",
       " 'Pork with lemon',\n",
       " 'Deep Fried Chicken Wing',\n",
       " 'Crispy Noodles',\n",
       " 'Fried spring rolls',\n",
       " 'Steamed rice roll',\n",
       " 'brownie',\n",
       " 'churro',\n",
       " 'chow mein',\n",
       " 'kung pao chicken',\n",
       " 'baked salmon']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOOD256_DIR = os.path.join(os.path.abspath(os.sep), \"Datasets\", \"food256\")\n",
    "\n",
    "class_names = []\n",
    "\n",
    "with open(os.path.join(FOOD256_DIR, \"condensed-category.txt\")) as file:\n",
    "    file.readline()\n",
    "    for line in file.readlines():\n",
    "        class_names.append(line.split('\\t')[1].strip())\n",
    "                           \n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fetch model architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching model architecture... done\n"
     ]
    }
   ],
   "source": [
    "print(\"Fetching model architecture... \", end=\"\")\n",
    "\n",
    "backbone = torchvision.models.mobilenet_v2(pretrained=False).features\n",
    "backbone.out_channels = 1280\n",
    "\n",
    "anchor_generator = torchvision.models.detection.rpn.AnchorGenerator(sizes=((32, 64, 128, 256, 512),), aspect_ratios=((0.5, 1.0, 2.0),))\n",
    "\n",
    "roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'], output_size=7, sampling_ratio=2)\n",
    "\n",
    "model = torchvision.models.detection.FasterRCNN(backbone, num_classes=len(class_names), rpn_anchor_generator=anchor_generator, box_roi_pool=roi_pooler)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load model weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading learnt model weights..."
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\OneDrive - Durham University\\\\Year 3\\\\Project\\\\Im2Calories\\\\notebooks\\\\food_detection\\\\models\\\\food_detection\\\\condensed\\\\mobilenet_backbone.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d8653f43112d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Loading learnt model weights...\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"done\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_open_zipfile_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\OneDrive - Durham University\\\\Year 3\\\\Project\\\\Im2Calories\\\\notebooks\\\\food_detection\\\\models\\\\food_detection\\\\condensed\\\\mobilenet_backbone.pt'"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = os.path.join(ROOT_DIR, \"models\", \"food_detection\", \"condensed\", \"mobilenet_backbone.pt\")\n",
    "\n",
    "print(\"Loading learnt model weights...\", end=\"\")\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load image from url**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImage(url):\n",
    "    filename = url.split('/')[-1]\n",
    "    img = utils.get_file(filename, url)\n",
    "    img = Image.open(img)\n",
    "    return img\n",
    "\n",
    "img = loadImage(\"https://ichef.bbci.co.uk/food/ic/food_16x9_832/recipes/fivespicespareribs_70976_16x9.jpg\")\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Format image for model input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom transform for R-CNN input\n",
    "class CustomTransform:\n",
    "    def __init__(self, image_size):\n",
    "        self.image_size = image_size\n",
    "        \n",
    "    def __call__(self, img):\n",
    "        # resize to a max of IMAGE_SIZE\n",
    "        w, h = img.size\n",
    "        scale = min(IMAGE_SIZE/w, IMAGE_SIZE/h)\n",
    "        img = transforms.functional.resize(img, (int(h*scale), int(w*scale)))\n",
    "        \n",
    "        # add padding to a size of IMAGE_SIZE\n",
    "        img = transforms.functional.pad(img, (0, 0, IMAGE_SIZE-int(w*scale), IMAGE_SIZE-int(h*scale)))\n",
    "        \n",
    "        # convert to tensor\n",
    "        img = transforms.functional.to_tensor(img)\n",
    "\n",
    "        # normalize\n",
    "        img = img / 255\n",
    "        return img\n",
    "\n",
    "transform = CustomTransform(image_size=IMAGE_SIZE)\n",
    "\n",
    "img = transform(img)\n",
    "images = img.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply model on image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(images):\n",
    "    images = images.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "results = predict(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Draw predicted bounding boxes on image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIDENCE_THRESHOLD = 0.8\n",
    "\n",
    "def drawResults(img, target):\n",
    "    fig, axis= plt.subplots(1)\n",
    "\n",
    "    img = np.transpose(img, (1,2,0))\n",
    "    img = img * 255\n",
    "    img = np.clip(img, 0, 1)\n",
    "    plt.imshow(img)\n",
    "\n",
    "    # draw results\n",
    "    for i in range(len(target[\"labels\"])):\n",
    "        if(target[\"scores\"][i] < CONFIDENCE_THRESHOLD):\n",
    "            break\n",
    "        \n",
    "        # draw bounding box\n",
    "        x1, y1, x2, y2 = target[\"boxes\"][i]\n",
    "        box = patches.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2, edgecolor='r', facecolor='none')\n",
    "        axis.add_patch(box)\n",
    "        axis.text(x1, y2, class_names[target[\"labels\"][i]], fontdict=dict(color='w', weight='bold'), bbox=dict(facecolor='r', edgecolor='none'))\n",
    "        foods.append(class_names[target[\"labels\"][i]])\n",
    "        \n",
    "    plt.show()\n",
    "\n",
    "foods = []\n",
    "drawResults(img, results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nutritional lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Search USDA for foods with predicted class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = UsdaClient(API_KEY)\n",
    "\n",
    "nutrients = {}\n",
    "\n",
    "for food_item in foods:\n",
    "    # seach USDA with predicted image class as search term\n",
    "    food_results = client.search_foods(food_item, 1)\n",
    "\n",
    "    food = next(food_results)\n",
    "\n",
    "    # fetch food report for top result\n",
    "    food_report = client.get_food_report(food.id)\n",
    "    \n",
    "    # add nutritional information to dictionary\n",
    "    for nutrient in food_report.nutrients:\n",
    "        key = \"{0} ({1})\".format(nutrient.name, nutrient.unit)\n",
    "        nutrients[key] = nutrients.get(key, 0) + nutrient.value\n",
    "    \n",
    "nutrients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
