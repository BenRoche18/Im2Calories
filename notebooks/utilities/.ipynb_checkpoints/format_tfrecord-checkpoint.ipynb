{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import math\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from object_detection.utils import dataset_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rice',\n",
       " \"chicken-'n'-egg on rice\",\n",
       " 'beef curry',\n",
       " 'sushi',\n",
       " 'chicken rice',\n",
       " 'fried rice',\n",
       " 'toast',\n",
       " 'croissant',\n",
       " 'roll bread',\n",
       " 'raisin bread',\n",
       " 'hamburger',\n",
       " 'pizza',\n",
       " 'sandwiches',\n",
       " 'spaghetti',\n",
       " 'vegetable tempura',\n",
       " 'sausage',\n",
       " 'omelet',\n",
       " 'stew',\n",
       " 'fried fish',\n",
       " 'grilled salmon',\n",
       " 'sweet and sour pork',\n",
       " 'tempura',\n",
       " 'fried chicken',\n",
       " 'steak',\n",
       " 'egg sunny-side up',\n",
       " 'roast chicken',\n",
       " 'fried shrimp',\n",
       " 'potato salad',\n",
       " 'green salad',\n",
       " 'pizza toast',\n",
       " 'hot dog',\n",
       " 'french fries',\n",
       " 'mixed rice',\n",
       " 'green curry',\n",
       " 'paella',\n",
       " 'pancake',\n",
       " 'crape',\n",
       " 'tiramisu',\n",
       " 'waffle',\n",
       " 'shortcake',\n",
       " 'mushroom risotto',\n",
       " 'french toast',\n",
       " 'minestrone',\n",
       " 'chicken nugget',\n",
       " 'french bread',\n",
       " 'bagel',\n",
       " 'scone',\n",
       " 'tortilla',\n",
       " 'tacos',\n",
       " 'nachos',\n",
       " 'meat loaf',\n",
       " 'scrambled egg',\n",
       " 'lasagna',\n",
       " 'Caesar salad',\n",
       " 'oatmeal',\n",
       " 'muffin',\n",
       " 'popcorn',\n",
       " 'doughnut',\n",
       " 'apple pie',\n",
       " 'lamb kebabs',\n",
       " 'roast duck',\n",
       " 'hot pot',\n",
       " 'pork belly',\n",
       " 'custard tart',\n",
       " 'stir-fried mixed vegetables',\n",
       " 'Pork with lemon',\n",
       " 'Deep Fried Chicken Wing',\n",
       " 'Crispy Noodles',\n",
       " 'Fried spring rolls',\n",
       " 'Steamed rice roll',\n",
       " 'brownie',\n",
       " 'churro',\n",
       " 'chow mein',\n",
       " 'kung pao chicken',\n",
       " 'baked salmon']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOOD256_DIR = os.path.join(os.path.abspath(os.sep), \"Datasets\", \"food256\")\n",
    "CLASS_PATH = os.path.join(FOOD256_DIR, \"condensed-category.txt\")\n",
    "\n",
    "with open(CLASS_PATH, 'r') as file:\n",
    "    file.readline()\n",
    "    class_names = [line.split('\\t')[1].strip() for line in file.readlines()]\n",
    "    \n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map dataset to sharded TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240 320 b'4284.jpg' b'jpg' [0.0] [0.0] [1.0] [1.0] [b'stew'] [18]\n",
      "614 406 b'155515.jpg' b'jpg' [0.13054187192118227] [0.0749185667752443] [0.9482758620689655] [0.9364820846905537] [b'roast duck'] [61]\n"
     ]
    }
   ],
   "source": [
    "ANNOTATIONS_DIR = os.path.join(FOOD256_DIR, \"Annotations\")\n",
    "IMAGES_DIR = os.path.join(FOOD256_DIR, \"condensed images\")\n",
    "SPLIT_DIR = os.path.join(FOOD256_DIR, \"ImageSets\", \"Main\")\n",
    "\n",
    "TRAIN_RECORDS_PATH = os.path.join(os.path.abspath(os.sep), \"Datasets\", \"food75\", \"train_dataset.record\")\n",
    "TEST_RECORDS_PATH = os.path.join(os.path.abspath(os.sep), \"Datasets\", \"food75\", \"test_dataset.record\")\n",
    "\n",
    "def format_example(example_id):\n",
    "    filename = example_id+\".jpg\"\n",
    "    img_path = os.path.join(IMAGES_DIR, filename)\n",
    "    lbl_path = os.path.join(ANNOTATIONS_DIR, example_id+\".xml\")\n",
    "    \n",
    "    tree = ET.parse(lbl_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # get image metadata\n",
    "    size = root.find('size')\n",
    "    width = int(size.find('width').text)\n",
    "    height = int(size.find('height').text)\n",
    "    \n",
    "    # read image as byte string\n",
    "    encoded_image_data = open(img_path, 'rb').read()\n",
    "    image_format = b\"jpg\"\n",
    "    \n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes = []\n",
    "    classes_text = []\n",
    "\n",
    "    # get object annotations\n",
    "    for obj in root.findall('object'):\n",
    "        class_name = obj.find('name').text\n",
    "        \n",
    "        # skip if class not in class_names\n",
    "        if class_name not in class_names:\n",
    "            continue\n",
    "        \n",
    "        # get bounding box\n",
    "        box = obj.find('bndbox')\n",
    "        x1 = int(box.find('xmin').text)\n",
    "        y1 = int(box.find('ymin').text)\n",
    "        x2 = int(box.find('xmax').text)\n",
    "        y2 = int(box.find('ymax').text)\n",
    "        \n",
    "        xmins.append(x1/width)\n",
    "        xmaxs.append(x2/width)\n",
    "        ymins.append(y1/height)\n",
    "        ymaxs.append(y2/height)\n",
    "        classes.append(class_names.index(class_name) + 1)\n",
    "        classes_text.append(str.encode(class_name))\n",
    "        \n",
    "    # return none if no objects in image\n",
    "    if len(classes) < 1:\n",
    "        return\n",
    "            \n",
    "    # encode filename as byte string\n",
    "    filename = str.encode(filename)\n",
    "    \n",
    "    return tf.train.Example(features=tf.train.Features(feature={\n",
    "      'image/height': dataset_util.int64_feature(height),\n",
    "      'image/width': dataset_util.int64_feature(width),\n",
    "      'image/filename': dataset_util.bytes_feature(filename),\n",
    "      'image/source_id': dataset_util.bytes_feature(filename),\n",
    "      'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n",
    "      'image/format': dataset_util.bytes_feature(image_format),\n",
    "      'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "      'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "      'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "      'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "      'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "      'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "  }))\n",
    "\n",
    "for split in [\"train\", \"test\"]:\n",
    "    with open(os.path.join(SPLIT_DIR, split+\".txt\"), 'r') as split_file:\n",
    "        with tf.io.TFRecordWriter(TRAIN_RECORDS_PATH if split == \"train\" else TEST_RECORDS_PATH) as writer:\n",
    "            for img_filename in split_file.readlines():\n",
    "                # format example and write to TFRecord\n",
    "                tf_example = format_example(img_filename.strip().replace(\".jpg\", \"\"))\n",
    "                \n",
    "                # skip if no class found\n",
    "                if tf_example:\n",
    "                    writer.write(tf_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create label map file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS_PATH = os.path.join(os.path.abspath(os.sep), \"Datasets\", \"food75\", \"label_map.pbtxt\")\n",
    "\n",
    "with open(LABELS_PATH, 'w') as file:\n",
    "    i = 1\n",
    "    for class_name in class_names:\n",
    "        line = \"item {{\\n  id: {0}\\n  name: '{1}'\\n}}\\n\\n\".format(i, class_name)\n",
    "        i += 1\n",
    "        file.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
