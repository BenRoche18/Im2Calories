{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.cElementTree as ET\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOOD256_DIR = os.path.join(os.path.abspath(os.sep), \"Datasets\", \"food256\")\n",
    "CLASS_PATH = os.path.join(FOOD256_DIR, \"category.txt\")\n",
    "\n",
    "with open(CLASS_PATH, 'r') as file:\n",
    "    file.readline()\n",
    "    class_names = [line.split('\\t')[1].strip() for line in file.readlines()]\n",
    "    \n",
    "len(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map annotations to VOC format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createBaseAnnotation(img_path, lbl_path):\n",
    "    # fetch image metadata\n",
    "    img = open(img_path, 'rb').read()\n",
    "    height, width, depth = tf.image.decode_jpeg(img).shape\n",
    "    \n",
    "    # create xml representation\n",
    "    annotation = ET.Element(\"annotation\")\n",
    "    ET.SubElement(annotation, \"filename\").text = img_path.split('\\\\')[-1]\n",
    "\n",
    "    size = ET.SubElement(annotation, \"size\")\n",
    "    ET.SubElement(size, \"width\").text = str(width)\n",
    "    ET.SubElement(size, \"height\").text = str(height)\n",
    "    ET.SubElement(size, \"depth\").text = str(depth)\n",
    "            \n",
    "    ET.SubElement(annotation, \"segmented\").text = '0'\n",
    "            \n",
    "    tree = ET.ElementTree(annotation)\n",
    "    tree.write(lbl_path)\n",
    "    \n",
    "    \n",
    "def addObjectAnnotation(lbl_path, lbl, x1, y1, x2, y2):\n",
    "    # read existing xml tree\n",
    "    tree = ET.parse(lbl_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    # add object information\n",
    "    obj = ET.SubElement(root, \"object\")\n",
    "    ET.SubElement(obj, \"name\").text = class_names[lbl-1]\n",
    "    box = ET.SubElement(obj, \"bndbox\")\n",
    "    ET.SubElement(box, \"xmin\").text = str(x1)\n",
    "    ET.SubElement(box, \"ymin\").text = str(y1)\n",
    "    ET.SubElement(box, \"xmax\").text = str(x2)\n",
    "    ET.SubElement(box, \"ymax\").text = str(y2)\n",
    "    \n",
    "    tree.write(lbl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATIONS_DIR = os.path.join(FOOD256_DIR, \"Annotations\")\n",
    "os.mkdir(ANNOTATIONS_DIR)\n",
    "\n",
    "for lbl in range(1, 257):\n",
    "    class_dir = os.path.join(FOOD256_DIR, str(lbl))\n",
    "    with open(os.path.join(class_dir, \"bb_info.txt\"), 'r') as file:\n",
    "        file.readline()\n",
    "        for line in file.readlines():\n",
    "            # fetch annotation\n",
    "            img_id, x1, y1, x2, y2 = line.split()\n",
    "            img_path = os.path.join(class_dir, img_id+\".jpg\")\n",
    "            lbl_path = os.path.join(ANNOTATIONS_DIR, img_id+\".xml\")\n",
    "            \n",
    "            # create base annotation if doesn't already exist\n",
    "            if not os.path.exists(lbl_path):\n",
    "                createBaseAnnotation(img_path, lbl_path)\n",
    "            \n",
    "            # add object annoation\n",
    "            addObjectAnnotation(lbl_path, lbl, x1, y1, x2, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge images into single directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_DIR = os.path.join(FOOD256_DIR, \"JPEGImages\")\n",
    "os.mkdir(IMAGES_DIR)\n",
    "\n",
    "for lbl in range(1, 257):\n",
    "    class_dir = os.path.join(FOOD256_DIR, str(lbl))\n",
    "    for img_path in os.listdir(class_dir):\n",
    "        if \".jpg\" in img_path:\n",
    "            # copy image to main JPEG images directory\n",
    "            os.rename(os.path.join(class_dir, img_path), os.path.join(IMAGES_DIR, img_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset split files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_DIR = os.path.join(FOOD256_DIR, \"ImageSets\", \"Main\")\n",
    "os.mkdir(os.path.dirname(SPLIT_DIR))\n",
    "os.mkdir(SPLIT_DIR)\n",
    "\n",
    "# read all image files\n",
    "images = os.listdir(IMAGES_DIR)\n",
    "random.shuffle(images)\n",
    "\n",
    "# take first 90% as training\n",
    "with open(os.path.join(SPLIT_DIR, \"train.txt\"), 'w') as file:\n",
    "    for img_path in images[:int(len(images)*0.9)]:\n",
    "        file.write(img_path+'\\n')\n",
    "        \n",
    "# take last 10% as validation\n",
    "with open(os.path.join(SPLIT_DIR, \"val.txt\"), 'w') as file:\n",
    "    for img_path in images[int(len(images)*0.9):]:\n",
    "        file.write(img_path+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
