{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU device not found\n",
      "Found GPU at: \n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  print('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "MODEL_PATH = os.path.join(ROOT_DIR, \"models\", \"binary_classification\", \"inception_v3\", \"transfer_learning.h5\")\n",
    "\n",
    "INPUT_SIZE = 299\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download 'non-food' dataset\n",
    "\n",
    "I will use a downsampled ImageNet dataset for the 'non-food' images since it's free to access and has the broadest variety of images. However the images are limited to a resolution of 64x64 and they aren't labelled, so the 51 food classes will be treated as 'non-food'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_food_test_raw = tfds.load(\"downsampled_imagenet/64x64\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download 'food' dataset\n",
    "\n",
    "I will the Food-101 dataset for the 'food' images, manually splitting with a 8:2 ratio of training to validation images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_test_raw = tfds.load(\"food101\", split=\"train[80:]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format and label the images\n",
    "\n",
    "Next, I will format the images for input into a convolutional neural network by rescaling the values between 0 & 1 and resizing to model input size. I will also label the data by labelling food images 1 and non-food images 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatImage(img):\n",
    "  img = tf.cast(img, tf.float32)\n",
    "  img /= 255\n",
    "  img = tf.image.resize_with_pad(img, INPUT_SIZE, INPUT_SIZE)\n",
    "  return img\n",
    "\n",
    "def formatNonFood(features):\n",
    "  img = features[\"image\"]\n",
    "  img = formatImage(img)\n",
    "  return img, 0\n",
    "\n",
    "def formatFood(features):\n",
    "  img = features[\"image\"]\n",
    "  img = formatImage(img)\n",
    "  return img, 1\n",
    "\n",
    "\n",
    "food_test_raw = food_test_raw.map(formatFood)\n",
    "non_food_test_raw = non_test_val_raw.map(formatNonFood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge datasets\n",
    "\n",
    "Concatenate the food and 'non-food' datsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw = food_test_raw.concatenate(non_food_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset\n",
    "\n",
    "Shuffle and batch the images ready for training on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batches = test_raw.batch(BATCH_SIZE, drop_remainder=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     multiple                  21802784  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  2049      \n",
      "=================================================================\n",
      "Total params: 21,804,833\n",
      "Trainable params: 2,049\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(MODEL_PATH, custom_objects={'KerasLayer':hub.KerasLayer})\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model on testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc == model.evaluate(test_batches)\n",
    "\n",
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
