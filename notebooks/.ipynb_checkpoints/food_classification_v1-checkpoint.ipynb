{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/BenRoche18/Im2Calories/blob/master/food_classification_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i_nLyDv8Vm2C"
   },
   "source": [
    "# Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ISJ0ihdNdjhS"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0wjsABqdVyKa"
   },
   "source": [
    "**Enable GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7rQNqPXEV4Ad"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Running on\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C8eHVTWDif9d"
   },
   "source": [
    "**Declare parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Y0qqicdirJ_"
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 299\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WUlZthLcWNJT"
   },
   "source": [
    "# Input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ylfT9aiQe-6J"
   },
   "source": [
    "**Download Food101 dataset**\n",
    "\n",
    "I will be using the labelled food-101 dataset that includes 101 different classes each containing 1000 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zXbE44oDfDGm"
   },
   "outputs": [],
   "source": [
    "FOOD101_DIR = os.path.join(\"food-101\")\n",
    "\n",
    "if \"food-101\" not in os.listdir():\n",
    "  print(\"Downloading Food-101 dataset... \", end=\"\")\n",
    "  !wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
    "  print(\"Done\")\n",
    "  print(\"Extracting data... \", end=\"\")\n",
    "  !tar xzvf food-101.tar.gz\n",
    "  print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ip_OHVgYkCft"
   },
   "source": [
    "**Split dataset into training and validation images**\n",
    "\n",
    "The dataset comes with a train and testing split defined in two seperate text files, however for faster access we will copy the respective images into train and test directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gQx5SruSkBUu"
   },
   "outputs": [],
   "source": [
    "FOOD101_DIR = \"food-101\"\n",
    "TRAIN_DIR = os.path.join(FOOD101_DIR, \"train\")\n",
    "VAL_DIR = os.path.join(FOOD101_DIR, \"test\")\n",
    "\n",
    "if not (os.path.exists)\n",
    "    print(\"Spliting dataset... \", end=\"\")\n",
    "    images = {}\n",
    "\n",
    "    for split in [\"train\", \"test\"]:\n",
    "      # extract image filenames\n",
    "      with open(os.path.join(FOOD101_DIR, \"meta\", split+\".txt\"), 'r') as file:\n",
    "        for path in file.readlines():\n",
    "          path = path.strip()\n",
    "          food_class, food_id = path.split('/')\n",
    "          images.setdefault(food_class, []).append(food_id)\n",
    "\n",
    "      # copy images into split directory\n",
    "      for food_class in images.keys():\n",
    "        # make class directory\n",
    "        class_dir = os.path.join(FOOD101_DIR, split, food_class)\n",
    "        if not os.path.exists(class_dir):\n",
    "          os.makedirs(class_dir)\n",
    "\n",
    "        # populate class directory with images\n",
    "        for food_id in images[food_class]:\n",
    "          src = os.path.join(FOOD101_DIR, \"images\", food_class, food_id+\".jpg\")\n",
    "          dest = os.path.join(FOOD101_DIR, split, food_class, food_id+\".jpg\")\n",
    "          if not os.path.exists(dest):\n",
    "            shutil.copy(src, dest)\n",
    "\n",
    "      images = {}\n",
    "\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sBhOjkemhk6g"
   },
   "source": [
    "**Format training images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ZebSYMpiVto"
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "  transforms.RandomResizedCrop(IMAGE_SIZE),\n",
    "  transforms.RandomHorizontalFlip(),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_raw = torchvision.datasets.ImageFolder(TRAIN_DIR, transform=train_transform)\n",
    "train_size = len(train_raw)\n",
    "print(train_size)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_raw, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "class_names = train_raw.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xKkckr8PlU33"
   },
   "source": [
    "**Format validation images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ijBl6GS2mAnV"
   },
   "outputs": [],
   "source": [
    "val_transform = transforms.Compose([\n",
    "  transforms.Resize(350),\n",
    "  transforms.CenterCrop(IMAGE_SIZE),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_raw = torchvision.datasets.ImageFolder(VAL_DIR, transform=val_transform)\n",
    "val_size = len(val_raw)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_raw, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PStaUYeqlk12"
   },
   "source": [
    "**Show example images from dataset**\n",
    "\n",
    "I have randomly selected and displayed 20 images from the training dataset along with their corresponding class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXJIlUvAmRJO"
   },
   "outputs": [],
   "source": [
    "cols, rows = 5, 4\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "fig.suptitle(\"Random images from dataset\")\n",
    "\n",
    "for i in range(1, cols*rows+1):\n",
    "  fig.add_subplot(rows, cols, i)\n",
    "\n",
    "  # randomly sellect image from dataset\n",
    "  j = np.random.randint(train_size)\n",
    "  img = train_raw[j][0].numpy()\n",
    "  img = np.transpose(img, (1,2,0))\n",
    "  img = img * (0.485, 0.456, 0.406) + (0.229, 0.224, 0.225)\n",
    "\n",
    "  plt.title(class_names[train_raw[j][1]])\n",
    "  plt.axis(\"off\")\n",
    "  img = np.clip(img, 0, 1)\n",
    "  plt.imshow(img, interpolation=\"nearest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xzgyw9d1YtJx"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IsiFng0jltpm"
   },
   "source": [
    "**Fetch Model**\n",
    "\n",
    "In order to train the food classifier I will initially use transfer learning from a pretrained InceptionV3 model. This involves replacing the classification head with a 101-way dense layer and freezing all other layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TBAfvknlm2kg"
   },
   "outputs": [],
   "source": [
    "# fetch pre-trained feature extractor\n",
    "model = torchvision.models.inception_v3(pretrained=True)\n",
    "\n",
    "# freeze feature extractor\n",
    "for param in model.parameters():\n",
    "  param.requires_grad = False\n",
    "\n",
    "model.aux_logits = False\n",
    "\n",
    "# extract number of features that are outputted in base model\n",
    "num_features = model.fc.in_features\n",
    "\n",
    "# replace classification head with 101-way dense layer\n",
    "model.fc = torch.nn.Linear(num_features, 101)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uvnnS8hWjPSV"
   },
   "source": [
    "# Training via transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xGOLOjPWHxtO"
   },
   "source": [
    "**Declare optimizer and loss function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iK1NBW85H1q0"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.fc.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
    "loss_func = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sg6d4uuPkWUM"
   },
   "source": [
    "**Train model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fu2zJKlTnTQe"
   },
   "outputs": [],
   "source": [
    "statistics = {\n",
    "    \"accuracy\": [],\n",
    "    \"val_accuracy\": []\n",
    "}\n",
    "\n",
    "def train():\n",
    "  best_acc = 0.0\n",
    "  best_model_weights = None\n",
    "\n",
    "  print(\"Training on {} images...\\n\".format(train_size))\n",
    "\n",
    "  for epoch in range(1, EPOCHS+1):\n",
    "    print(\"Epoch {}/{}...\".format(epoch, EPOCHS))\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for (images, labels) in train_loader:\n",
    "      images = images.to(device)\n",
    "      labels = labels.to(device)\n",
    "\n",
    "      # reset the parameter gradients\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # fit images on model\n",
    "      outputs = model(images)\n",
    "      _, predictions = torch.max(outputs, 1)\n",
    "      loss = loss_func(outputs, labels)\n",
    "\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      running_loss += loss.item() * images.size(0)\n",
    "      running_corrects += torch.sum(predictions == labels.data)\n",
    "\n",
    "    # calculate statistics\n",
    "    epoch_loss = running_loss / train_size\n",
    "    epoch_acc = running_corrects.double() / train_size\n",
    "    \n",
    "    # print statistics\n",
    "    print(\"Training Loss: {:.4f}, Acc: {:.4f}\".format(epoch_loss, epoch_acc))\n",
    "\n",
    "    val_loss, val_acc = validate()\n",
    "\n",
    "    # save best model seen\n",
    "    if val_acc > best_acc:\n",
    "      best_acc = epoch_acc\n",
    "      best_model_weights = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    # print statistics\n",
    "    print(\"Validation Loss: {:.4f}, Acc: {:.4f}\\n\".format(val_loss, val_acc))\n",
    "\n",
    "  # reinstantiate best seen weights\n",
    "  model.load_state_dict(best_model_weights)\n",
    "\n",
    "  print(\"DONE\")\n",
    "\n",
    "\n",
    "def validate():\n",
    "  model.eval()\n",
    "  running_loss = 0.0\n",
    "  running_corrects = 0\n",
    "\n",
    "  for (images, labels) in val_loader:\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # fit images on model\n",
    "    with torch.no_grad():\n",
    "      outputs = model(images)\n",
    "      _, predictions = torch.max(outputs, 1)\n",
    "      loss = loss_func(outputs, labels)\n",
    "\n",
    "    running_loss += loss.item() * images.size(0)\n",
    "    running_corrects += torch.sum(predictions == labels.data)\n",
    "\n",
    "  # calculate statistics\n",
    "  val_loss = running_loss / val_size\n",
    "  val_acc = running_corrects.double() / val_size\n",
    "\n",
    "  return val_loss, val_acc\n",
    "\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "toIULLBt1TBP"
   },
   "source": [
    "**Save model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f407af0g1ZsG"
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = os.path.join(\"models\", \"food_classifier_TL_v1.pt\")\n",
    "\n",
    "torch.save(model.state_dict(), MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4xGyA_WZrFd1"
   },
   "source": [
    "**Evaluate transfer learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7J0iqj-OrIqS"
   },
   "outputs": [],
   "source": [
    "plt.plot(statistics['accuracy'], label='accuracy')\n",
    "plt.plot(statistics['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I03gKxB1HNrs"
   },
   "source": [
    "# Training via fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bsIvaCgRMEad"
   },
   "source": [
    "**Unfreeze layers in model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lJ3e1KtmMHjF"
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "  param.requires_grad = True\n",
    "\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_3wLFxYsLUNd"
   },
   "source": [
    "**Train model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lS1wVjE3MDp2"
   },
   "outputs": [],
   "source": [
    "statistics = {\n",
    "    \"accuracy\": [],\n",
    "    \"val_accuracy\": []\n",
    "}\n",
    "\n",
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M8HmApoDkel8"
   },
   "source": [
    "**Save model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KNXCBYEGkel9"
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = os.path.join(\"models\", \"food_classifier_FT_v2\")\n",
    "\n",
    "torch.save(model.state_dict(), MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9wHQgtDmp2nK"
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B52JjtGBp4ZK"
   },
   "outputs": [],
   "source": [
    "plt.plot(statistics['accuracy'], label='accuracy')\n",
    "plt.plot(statistics['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMEED9oymhB2SYDFZhAXOf8",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "food_classification_v1.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
