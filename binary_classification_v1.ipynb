{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "binary_classification_v1.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPIMk7VMIZmUNj0LwueFLiU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenRoche18/Im2Calories/blob/master/binary_classification_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEcUFYXM2aSx",
        "colab_type": "text"
      },
      "source": [
        "# Set up environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEYIVsXM2Nxf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kmhg-R4zPWRh",
        "colab_type": "text"
      },
      "source": [
        "**Mount google drive**\n",
        "\n",
        "Mount google drive that contains project files and set to working directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpqxfH_tbscH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "PROJECT_DIR = os.path.join(\"drive\", \"My Drive\", \"Im2Calories\")\n",
        "os.chdir(PROJECT_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfcRypx06pmo",
        "colab_type": "text"
      },
      "source": [
        "**Enable GPU**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DcUfW8x6fLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPtReFx-_XqJ",
        "colab_type": "text"
      },
      "source": [
        "**Declare parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1sTuOAH_bfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_SIZE = 299\n",
        "SHUFFLE_BUFFER_SIZE = 1000\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 1\n",
        "LEARNING_RATE = 0.0001\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
        "loss_func = \"binary_crossentropy\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ybq9Go2B5S6h",
        "colab_type": "text"
      },
      "source": [
        "# Input data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOwIdJoF7TFx",
        "colab_type": "text"
      },
      "source": [
        "**Download 'non-food' dataset**\n",
        "\n",
        "I will use a downsampled ImageNet dataset for the 'non-food' images since it's free to access and has the broadest variety of images. However the images are limited to a resolution of 64x64 and they aren't labelled, so the 51 food classes will be treated as 'non-food'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1hA4nrp7REK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "non_food_train_raw = tfds.load(\"downsampled_imagenet/64x64\", split=\"train\")\n",
        "non_food_val_raw = tfds.load(\"downsampled_imagenet/64x64\", split=\"validation\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LmSAfiLl98I8"
      },
      "source": [
        "**Download 'food' dataset**\n",
        "\n",
        "I will the Food-101 dataset for the 'food' images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PzyWzpfl98I-",
        "colab": {}
      },
      "source": [
        "food_train_raw = tfds.load(\"food101\", split=\"train[:80]\")\n",
        "food_val_raw = tfds.load(\"food101\", split=\"train[80:]\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNhBUBxVAebI",
        "colab_type": "text"
      },
      "source": [
        "**Reduce datasets**\n",
        "\n",
        "As this is only a binary classification, it is unnecessary to use the full datasets and we also need to ensure there are the same number of 'non-food' images as food images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMqNHyyaA1VB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAINING_SIZE = 100000\n",
        "VAL_SIZE = 10000\n",
        "\n",
        "food_train_raw = food_train_raw.shuffle(SHUFFLE_BUFFER_SIZE).take(TRAINING_SIZE//2)\n",
        "non_food_train_raw = non_food_train_raw.shuffle(SHUFFLE_BUFFER_SIZE).take(TRAINING_SIZE//2)\n",
        "food_val_raw = food_val_raw.shuffle(SHUFFLE_BUFFER_SIZE).take(VAL_SIZE//2)\n",
        "non_food_val_raw = non_food_val_raw.shuffle(SHUFFLE_BUFFER_SIZE).take(VAL_SIZE//2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70946PYe-nIY",
        "colab_type": "text"
      },
      "source": [
        "**Format and label the images**\n",
        "\n",
        "Next, I will format the images for input into a convolutional neural network by rescaling the values between 0 & 1 and resizing to model input size. I will also label the data by labelling food images 1 and non-food images 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14UAPmrR_KDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def formatImage(img):\n",
        "  img = tf.cast(img, tf.float32)\n",
        "  img /= 255\n",
        "  img = tf.image.resize_with_pad(img, INPUT_SIZE, INPUT_SIZE)\n",
        "  return img\n",
        "\n",
        "def formatNonFood(features):\n",
        "  img = features[\"image\"]\n",
        "  img = formatImage(img)\n",
        "  return img, 0\n",
        "\n",
        "def formatFood(features):\n",
        "  img = features[\"image\"]\n",
        "  img = formatImage(img)\n",
        "  return img, 1\n",
        "\n",
        "food_train_raw = food_train_raw.map(formatFood)\n",
        "food_val_raw = food_val_raw.map(formatFood)\n",
        "non_food_train_raw = non_food_train_raw.map(formatNonFood)\n",
        "non_food_val_raw = non_food_val_raw.map(formatNonFood)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UU6JVwIGBkIJ",
        "colab_type": "text"
      },
      "source": [
        "**Merge datasets**\n",
        "\n",
        "Concatenate the food and 'non-food' datsets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhlEPa1RBvRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_raw = food_train_raw.concatenate(non_food_train_raw)\n",
        "val_raw = food_val_raw.concatenate(non_food_val_raw)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUC3hsGZDdTm",
        "colab_type": "text"
      },
      "source": [
        "**Prepare dataset**\n",
        "\n",
        "Shuffle and batch the images ready for training on the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrBsSHs4DcSo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batches = train_raw.shuffle(TRAINING_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "val_batches = val_raw.batch(BATCH_SIZE, drop_remainder=True) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWHmXNUfDpUO",
        "colab_type": "text"
      },
      "source": [
        "**Show example images**\n",
        "\n",
        "Randomly select and display 20 images from the dataset along with their class (i.e. food or 'non-food')."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXl07ZJTD8tO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols, rows = 4, 5\n",
        "fig = plt.figure(figsize=(20,10))\n",
        "fig.suptitle(\"Random images from dataset\")\n",
        "\n",
        "examples = train_batches.unbatch().batch(20).as_numpy_iterator()\n",
        "\n",
        "images, labels = next(examples)\n",
        "\n",
        "for i in range(1, cols*rows+1):\n",
        "  fig.add_subplot(rows, cols, i)\n",
        "\n",
        "  img = images[i-1]\n",
        "\n",
        "  if labels[i-1] == 1:\n",
        "    plt.title(\"food\")\n",
        "  else:\n",
        "    plt.title(\"non-food\")\n",
        "\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(img, interpolation=\"nearest\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xF2Zt_e65WJp",
        "colab_type": "text"
      },
      "source": [
        "# Model\n",
        "\n",
        "In order to train a binary classifier we take a pretrainied Inception model on the ImageNet dataset and replace the classification head with a single logistic node."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFQiupNaFUm-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = tf.keras.applications.InceptionV3(include_top=False)\n",
        "base_model.trainable = False\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_func, metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HQWf8t86NXY",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ucNVGPST-IC",
        "colab_type": "text"
      },
      "source": [
        "**Train the classification head**\n",
        "\n",
        "I now train the classification head of the model on the dataset as the feature extractor part of the model has been frozen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKIYeeP3Hd_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(train_batches, validation_data=val_batches, epochs=EPOCHS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKUjlhEoH1Qd",
        "colab_type": "text"
      },
      "source": [
        "**Save model weights**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMoglSi_H38O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_PATH = os.path.join(\"models\", \"binary_classifier_v1.h5\")\n",
        "model.save(MODEL_PATH, overwrite=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeJ2ByasT4iT",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O517ah6plDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}